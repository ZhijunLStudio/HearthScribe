# main.py
import os
# ç¦ç”¨ä¸€äº›å¯èƒ½å¯¼è‡´å†²çªçš„å¹¶è¡Œåº“è®¾ç½®
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["KMP_DUPLICATE_LIB_OK"] = "True"

import time
import logging
import sys
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import cv2
import config

# æ—¥å¿—æ ¼å¼
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', handlers=[logging.StreamHandler(sys.stdout)])

def main():
    print("\n=== HearthScribe ç©ºé—´æŒ‡æŒ¥èˆ±å¯åŠ¨ (é«˜æ€§èƒ½ç‰ˆ) ===\n")

    # 1. åˆå§‹åŒ–æ¨¡å—
    try:
        from src.perception.perception_processor import PerceptionProcessor
        # åŠ è½½æ„ŸçŸ¥æ¨¡å—
        perception = PerceptionProcessor(index_dir=config.FACE_INDEX_DIR)
        
        from src.memory.memory_stream import MemoryStream
        memory_stream = MemoryStream(config.IMAGE_STORAGE_PATH)
        
        from src.memory.long_term_memory import LongTermMemory
        print("  [Init] æ­£åœ¨è¿æ¥è®°å¿†åº“...")
        ltm = LongTermMemory(config.LANCEDB_PATH, config.SQLITE_DB_PATH)
        
        from src.cognition.cognitive_core import CognitiveCore
        cognition = CognitiveCore()
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # 2. æ‘„åƒå¤´
    cap = cv2.VideoCapture(config.SOURCE_VIDEO)
    if not cap.isOpened():
        print("âŒ æ‘„åƒå¤´æ•…éšœ")
        return
    
    # è®¾ç½®æ‘„åƒå¤´ç¼“å†²åŒºå¤§å°ä¸º1ï¼Œä¿è¯è¯»åˆ°çš„æ˜¯æœ€æ–°å¸§ï¼ˆå‡å°‘å»¶è¿Ÿï¼‰
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    print(f"\nâœ… æ‘„åƒå¤´å°±ç»ª | ç­–ç•¥: åŸºäºæ—¶é—´æˆ³ï¼Œæ¯ {config.PROCESS_INTERVAL} ç§’æ£€æµ‹ä¸€æ¬¡")

    executor = ThreadPoolExecutor(max_workers=1)
    
    # --- å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨æ—¶é—´æˆ³æ§åˆ¶é¢‘ç‡ ---
    last_process_time = 0 
    
    try:
        while True:
            # è¯»å–ä¸€å¸§
            ret, frame = cap.read()
            if not ret: 
                time.sleep(0.1)
                continue
            
            current_time = time.time()
            
            # åªæœ‰å½“ (å½“å‰æ—¶é—´ - ä¸Šæ¬¡æ£€æµ‹æ—¶é—´) > è®¾å®šé—´éš” (2ç§’) æ—¶ï¼Œæ‰æ£€æµ‹
            if current_time - last_process_time >= config.PROCESS_INTERVAL:
                
                last_process_time = current_time # æ›´æ–°æ—¶é—´æˆ³
                current_time_str = datetime.now().strftime("%H:%M:%S")
                
                # --- ä¼˜åŒ–ï¼šç¼©å°å›¾ç‰‡è¿›è¡Œæ£€æµ‹ (å¤§å¹…æå‡é€Ÿåº¦) ---
                # ä¿æŒåŸå›¾ frame ç”¨äºä¿å­˜å’Œæ˜¾ç¤ºï¼Œå¤åˆ¶ä¸€ä¸ªå°å›¾ small_frame ç”¨äºæ£€æµ‹
                # å®½åº¦ç¼©æ”¾åˆ° 640ï¼Œé«˜åº¦æŒ‰æ¯”ä¾‹
                h, w = frame.shape[:2]
                scale = 640 / w
                small_frame = cv2.resize(frame, (0, 0), fx=scale, fy=scale)
                
                # A. æ„ŸçŸ¥ (ä¼ å…¥å°å›¾ï¼Œé€Ÿåº¦æ›´å¿«)
                # æ³¨æ„ï¼šPerceptionProcessor å†…éƒ¨è¿”å›çš„åæ ‡æ˜¯åŸºäºå°å›¾çš„
                # å¦‚æœéœ€è¦ç²¾ç¡®åæ ‡ç”»åœ¨åŸå›¾ä¸Šï¼Œéœ€è¦æŠŠåæ ‡ * (1/scale) è¿˜åŸ
                # ä½†å¯¹äºç›®å‰çš„é€»è¾‘ï¼Œåªè¦æ£€æµ‹åˆ°äººå°±è¡Œï¼Œåæ ‡ç•¥æœ‰åå·®å½±å“ä¸å¤§
                detections = perception.process_frame(small_frame)
                
                # B. åé¦ˆçŠ¶æ€
                if not detections:
                    print(f"[{current_time_str}] ğŸ’¤ ç©ºé—´é—²ç½®ä¸­...", end='\r')
                else:
                    # å¦‚æœéœ€è¦ä¿å­˜åŸå›¾ï¼Œè¿™é‡Œè¿˜æ˜¯ä¼ åŸå›¾ç»™ MemoryStream
                    # æ³¨æ„ï¼šå¦‚æœ detections æ˜¯åŸºäºå°å›¾çš„ï¼ŒMemoryStream ç”»æ¡†å¯èƒ½ä¼šåå°
                    # ç®€å•ä¿®å¤ï¼šæŠŠ detections é‡Œçš„ box åæ ‡è¿˜åŸ
                    for det in detections:
                        if 'box' in det:
                            det['box'] = [int(c / scale) for c in det['box']]
                        if 'face_box' in det and det['face_box']:
                            det['face_box'] = [int(c / scale) for c in det['face_box']]

                    # C. è®°å¿†æµå¤„ç† (ä¼ å…¥é«˜æ¸…åŸå›¾)
                    event_pack = memory_stream.update(frame, detections)
                    
                    # D. äº‹ä»¶æ‰“åŒ… -> åå°åˆ†æ
                    if event_pack:
                        duration = event_pack['end_time'] - event_pack['start_time']
                        print(f"\nğŸ“¦ [{current_time_str}] ç”Ÿæˆäº‹ä»¶ç‰‡æ®µ ({duration:.1f}s) -> æäº¤å¤§è„‘åˆ†æ")
                        executor.submit(bg_analyze, event_pack, cognition, ltm)

            # è¿™é‡Œçš„ sleep å¯ä»¥éå¸¸çŸ­ï¼Œæˆ–è€…ç›´æ¥å»æ‰ï¼Œå› ä¸ºä¸Šé¢æœ‰ cap.read() é˜»å¡
            time.sleep(0.01)

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç³»ç»Ÿåœæ­¢")
    finally:
        cap.release()
        executor.shutdown(wait=False)

def bg_analyze(event, cognition, ltm):
    """åå°åˆ†æçº¿ç¨‹"""
    try:
        result = cognition.analyze_event(event)
        if result:
            success = ltm.save_event(
                event_data=event, 
                summary=result['summary'], 
                kg_data=result['kg_data'],
                scene_label=result.get('scene_label'),
                interaction_score=result.get('interaction_score')
            )
            if success:
                print(f"ğŸ’¾ [å…¥åº“] {result.get('scene_label')} | è¯„åˆ†:{result.get('interaction_score')} | {result['summary'][:15]}...")
    except Exception as e:
        print(f"âŒ [åå°å¼‚å¸¸] {e}")

if __name__ == "__main__":
    main()