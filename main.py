# main.py
import os
# ç¦ç”¨å¹¶è¡Œåº“å†²çªè­¦å‘Š
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["KMP_DUPLICATE_LIB_OK"] = "True"

import time
import logging
import sys
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import cv2
import config

# æ—¥å¿—æ ¼å¼
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', handlers=[logging.StreamHandler(sys.stdout)])

# --- æ ¸å¿ƒä¿®å¤ï¼šæ— é˜»å¡æ‘„åƒå¤´è¯»å–ç±» ---
class CameraLoader:
    def __init__(self, src=0):
        self.cap = cv2.VideoCapture(src)
        if not self.cap.isOpened():
            raise Exception("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        
        # è®¾ç½®ç¼“å†²åŒºå¤§å°ä¸º1ï¼ˆå°è¯•ç‰©ç†å‡å°‘å»¶è¿Ÿï¼‰
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        self.grabbed, self.frame = self.cap.read()
        self.started = False
        self.read_lock = threading.Lock()

    def start(self):
        if self.started: return self
        self.started = True
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.daemon = True
        self.thread.start()
        return self

    def update(self):
        while self.started:
            grabbed, frame = self.cap.read()
            with self.read_lock:
                self.grabbed = grabbed
                self.frame = frame
            # æçŸ­çš„ä¼‘çœ ï¼Œé¿å…æ­»å¾ªç¯å æ»¡ CPUï¼Œä½†è¦è¶³å¤Ÿå¿«ä»¥æ¸…ç©º Buffer
            time.sleep(0.005) 

    def read(self):
        with self.read_lock:
            if not self.grabbed: return None
            return self.frame.copy()

    def stop(self):
        self.started = False
        if self.thread.is_alive():
            self.thread.join()
        self.cap.release()

def main():
    print("\n=== HearthScribe ç©ºé—´æŒ‡æŒ¥èˆ±å¯åŠ¨ (é›¶å»¶è¿Ÿç‰ˆ) ===\n")

    # 1. åˆå§‹åŒ–æ¨¡å—
    try:
        from src.perception.perception_processor import PerceptionProcessor
        perception = PerceptionProcessor(index_dir=config.FACE_INDEX_DIR)
        
        from src.memory.memory_stream import MemoryStream
        memory_stream = MemoryStream(config.IMAGE_STORAGE_PATH)
        
        from src.memory.long_term_memory import LongTermMemory
        print("  [Init] æ­£åœ¨è¿æ¥è®°å¿†åº“...")
        ltm = LongTermMemory(config.LANCEDB_PATH, config.SQLITE_DB_PATH)
        
        from src.cognition.cognitive_core import CognitiveCore
        cognition = CognitiveCore()
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # 2. å¯åŠ¨æ‘„åƒå¤´çº¿ç¨‹
    try:
        print(f"\nğŸ¥ æ­£åœ¨å¯åŠ¨æ‘„åƒå¤´çº¿ç¨‹ (Source: {config.SOURCE_VIDEO})...")
        cam_loader = CameraLoader(config.SOURCE_VIDEO).start()
        print(f"âœ… æ‘„åƒå¤´å°±ç»ª | ç­–ç•¥: å®æ—¶è·å–æœ€æ–°å¸§")
    except Exception as e:
        print(f"âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥: {e}")
        return

    executor = ThreadPoolExecutor(max_workers=1)
    last_process_time = 0 
    
    try:
        while True:
            # ç›´æ¥è·å–æœ€æ–°ä¸€å¸§ (Zero Latency)
            frame = cam_loader.read()
            
            if frame is None: 
                time.sleep(0.1)
                continue
            
            current_time = time.time()
            
            # æ§åˆ¶æ£€æµ‹é¢‘ç‡
            if current_time - last_process_time >= config.PROCESS_INTERVAL:
                
                last_process_time = current_time
                current_time_str = datetime.now().strftime("%H:%M:%S")
                
                # --- å›¾åƒç¼©æ”¾åŠ é€Ÿ ---
                h, w = frame.shape[:2]
                scale = 640 / w
                small_frame = cv2.resize(frame, (0, 0), fx=scale, fy=scale)
                
                # A. æ„ŸçŸ¥
                detections = perception.process_frame(small_frame)
                
                # B. åæ ‡è¿˜åŸ & çŠ¶æ€åé¦ˆ
                if not detections:
                    print(f"[{current_time_str}] ğŸ’¤ ç©ºé—´é—²ç½®ä¸­...", end='\r')
                else:
                    # è¿˜åŸåæ ‡åˆ°åŸå›¾å°ºå¯¸
                    for det in detections:
                        if 'box' in det:
                            det['box'] = [int(c / scale) for c in det['box']]
                        if 'face_box' in det and det['face_box']:
                            det['face_box'] = [int(c / scale) for c in det['face_box']]

                    # C. è®°å¿†æµ
                    event_pack = memory_stream.update(frame, detections)
                    
                    # D. åå°åˆ†æ
                    if event_pack:
                        duration = event_pack['end_time'] - event_pack['start_time']
                        print(f"\nğŸ“¦ [{current_time_str}] ç”Ÿæˆäº‹ä»¶ç‰‡æ®µ ({duration:.1f}s) -> æäº¤å¤§è„‘åˆ†æ")
                        executor.submit(bg_analyze, event_pack, cognition, ltm)

            time.sleep(0.01)

    except KeyboardInterrupt:
        print("\nğŸ›‘ ç³»ç»Ÿåœæ­¢")
    finally:
        cam_loader.stop()
        executor.shutdown(wait=False)

def bg_analyze(event, cognition, ltm):
    """åå°åˆ†æçº¿ç¨‹"""
    try:
        result = cognition.analyze_event(event)
        if result:
            success = ltm.save_event(
                event_data=event, 
                summary=result['summary'], 
                kg_data=result['kg_data'],
                scene_label=result.get('scene_label'),
                interaction_score=result.get('interaction_score')
            )
            if success:
                # æ‰“å°æ›´è¯¦ç»†çš„æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
                label = result.get('scene_label')
                score = result.get('interaction_score')
                print(f"ğŸ’¾ [å…¥åº“] {label} (Score:{score}) | {result['summary'][:20]}...")
    except Exception as e:
        print(f"âŒ [åå°å¼‚å¸¸] {e}")

if __name__ == "__main__":
    main()