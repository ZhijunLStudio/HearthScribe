import logging
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import json
import re
import networkx as nx
from pyvis.network import Network

# ç¡®ä¿èƒ½æ‰¾åˆ°srcç›®å½•
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import config
from src.memory.long_term_memory import LongTermMemory
from src.agent.master_agent import MasterAgent

logger = logging.getLogger(__name__)

# --- å•ä¾‹æ¨¡å¼å®ä¾‹åŒ– ---
_memory_instance = None
_master_agent_instance = None

def get_memory_instance():
    global _memory_instance
    if _memory_instance is None:
        try:
            logger.info("Initializing LongTermMemory instance for web app...")
            _memory_instance = LongTermMemory(config.LANCEDB_PATH, config.SQLITE_DB_PATH)
        except Exception as e:
            logger.error(f"Failed to initialize LongTermMemory: {e}", exc_info=True)
    return _memory_instance

def get_master_agent():
    global _master_agent_instance
    if _master_agent_instance is None:
        memory = get_memory_instance()
        if memory:
            logger.info("Initializing MasterAgent instance for web app...")
            _master_agent_instance = MasterAgent(memory)
    return _master_agent_instance

# --- å…¨å±€å®ä¾‹ ---
MEMORY = get_memory_instance()
MASTER_AGENT = get_master_agent()

# --- æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def parse_summary(raw_summary):
    """
    è§£ææ‰©å±•æ‘˜è¦ï¼Œæå–æ–‡æœ¬ã€æ ‡ç­¾å’Œè¯„åˆ†ã€‚
    è¾“å…¥æ ¼å¼: "æ‘˜è¦æ–‡æœ¬...|||LABEL:xxx|||SCORE:5"
    """
    if not raw_summary: return "", "æœªçŸ¥", 0
    
    parts = raw_summary.split("|||")
    text = parts[0]
    label = "æ—¥å¸¸"
    score = 0
    
    for p in parts:
        if p.startswith("LABEL:"): 
            label = p.replace("LABEL:", "")
        if p.startswith("SCORE:"): 
            try: score = int(p.replace("SCORE:", ""))
            except: pass
            
    return text, label, score

# --- æ•°æ®èšåˆä¸ç»Ÿè®¡ (Dashboard) ---

def get_dashboard_stats():
    """è·å–çœ‹æ¿æ‰€éœ€çš„ 4 ä¸ªæ ¸å¿ƒæŒ‡æ ‡"""
    if not MEMORY: return {}
    
    stats = {
        "event_count": 0,
        "risk_count": 0,
        "max_inactive_min": 0,
        "rest_hours": 0.0,
        "last_active": "--:--"
    }
    
    today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).timestamp()
    
    try:
        with MEMORY.db_lock:
            cursor = MEMORY.sqlite_conn.cursor()
            
            # 1. è·å–ä»Šæ—¥æ‰€æœ‰äº‹ä»¶
            cursor.execute("SELECT start_time, end_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
            rows = cursor.fetchall()
            
            stats["event_count"] = len(rows)
            
            if rows:
                max_gap = 0
                rest_sec = 0
                risk_alerts = 0
                last_end = rows[0][1]
                
                for i, r in enumerate(rows):
                    start, end, summary = r[0], r[1], r[2]
                    text, label, _ = parse_summary(summary)
                    
                    # ç»Ÿè®¡é£é™©
                    if "è·Œå€’" in text or "é£é™©" in label or "æ±‚æ•‘" in text:
                        risk_alerts += 1
                        
                    # ç»Ÿè®¡ä¼‘æ¯ (æ ‡ç­¾åŒ…å«å•äººä¸”æ–‡æœ¬æœ‰ç¡/èºº)
                    if "èºº" in text or "ç¡" in text or "ä¼‘æ¯" in text:
                        rest_sec += (end - start)
                        
                    # ç»Ÿè®¡é™æ­¢é—´éš”
                    if i > 0:
                        gap = start - last_end
                        if gap > max_gap: max_gap = gap
                    last_end = end
                
                # å½“å‰æ—¶åˆ»è·ç¦»æœ€åä¸€ä¸ªäº‹ä»¶çš„é—´éš”
                curr_gap = datetime.now().timestamp() - rows[-1][1]
                if curr_gap > max_gap: max_gap = curr_gap
                
                stats["max_inactive_min"] = int(max_gap / 60)
                stats["rest_hours"] = round(rest_sec / 3600, 1)
                stats["risk_count"] = risk_alerts
                stats["last_active"] = datetime.fromtimestamp(rows[-1][0]).strftime("%H:%M")
                
    except Exception as e:
        logger.error(f"Stats Error: {e}")
        
    return stats

def get_interaction_trend():
    """è·å–äº¤äº’çƒ­åº¦æ›²çº¿æ•°æ® (DataFrame)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT start_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
        rows = cursor.fetchall()
        
    data = []
    for r in rows:
        _, _, score = parse_summary(r[1])
        data.append({
            "Time": datetime.fromtimestamp(r[0]).strftime("%H:%M"),
            "Score": score
        })
    return pd.DataFrame(data)

def get_scene_distribution():
    """è·å–åœºæ™¯æ ‡ç­¾åˆ†å¸ƒ (DataFrame)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT summary FROM events WHERE start_time >= ?", (today_start,))
        rows = cursor.fetchall()
        
    labels = []
    for r in rows:
        _, label, _ = parse_summary(r[0])
        labels.append(label)
        
    if not labels: return pd.DataFrame()
    df = pd.DataFrame(labels, columns=["Type"])
    return df["Type"].value_counts().reset_index(name="Count").rename(columns={"index": "Type"}) # Pandas å…¼å®¹æ€§å†™æ³•

def get_person_frequency():
    """è·å–äººå‘˜å‡ºç°é¢‘ç‡ (DataFrame)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("""
            SELECT e.name FROM entities e
            JOIN relationships r ON e.id = r.source_id OR e.id = r.target_id
            JOIN events ev ON r.event_id = ev.event_id
            WHERE ev.start_time >= ? AND e.type = 'Person' AND e.name != 'Unknown_Body'
        """, (today_start,))
        rows = cursor.fetchall()
    
    names = [r[0] for r in rows]
    if not names: return pd.DataFrame()
    
    df = pd.DataFrame(names, columns=["Name"])
    return df["Name"].value_counts().reset_index(name="Count").rename(columns={"index": "Name"})

def get_system_stats():
    """è·å–ç³»ç»Ÿç¡¬æŒ‡æ ‡"""
    if not MEMORY: return {"memory": 0, "entities": 0, "care_hours": "0.0h"}
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM events")
        mem = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM entities")
        ent = cursor.fetchone()[0]
        cursor.execute("SELECT SUM(end_time - start_time) FROM events")
        row = cursor.fetchone()
        total_sec = row[0] if row[0] else 0
        
    return {
        "memory": mem,
        "entities": ent,
        "care_hours": f"{total_sec/3600:.1f}h"
    }

# --- é—®ç­” & æŠ¥å‘Š & å›¾è°± ---

def agent_answer_stream(query):
    """æµå¼è¿”å› Agent å›ç­”"""
    if not MASTER_AGENT:
        yield "System Initializing..."
        return
    # ä½¿ç”¨ execute_query_stepsï¼Œè€Œä¸æ˜¯ä¸å­˜åœ¨çš„ execute_query
    gen = MASTER_AGENT.execute_query_steps(query, lambda x: None)
    for step in gen:
        if step['status'] in ['generating', 'done']:
            yield step['content']

def generate_daily_report_content(date_obj=None):
    """ç”Ÿæˆ Markdown æ—¥æŠ¥"""
    if not MEMORY: return "No Data"
    if not date_obj: date_obj = datetime.now()
    
    start_ts = datetime.combine(date_obj, datetime.min.time()).timestamp()
    end_ts = datetime.combine(date_obj, datetime.max.time()).timestamp()
    
    # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨çš„æ˜¯ LongTermMemory æ–°è¡¥å…¨çš„ get_events_for_period
    events = MEMORY.get_events_for_period(start_ts, end_ts)
    
    if not events: return f"## ğŸ“… {date_obj.strftime('%Y-%m-%d')} æŠ¥å‘Š\n\nå½“æ—¥æ— è®°å½•ã€‚"
    
    md = [f"# ğŸ“… {date_obj.strftime('%Y-%m-%d')} æ™ºèƒ½çœ‹æŠ¤æŠ¥å‘Š\n"]
    md.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}\n")
    md.append(f"**äº‹ä»¶æ€»æ•°**: {len(events)}\n")
    md.append("## ğŸ“ è¯¦ç»†æ—¶é—´çº¿")
    
    for e in events:
        t = datetime.fromtimestamp(e['start_time']).strftime('%H:%M')
        txt, lbl, _ = parse_summary(e['summary'])
        md.append(f"- **{t}** `[{lbl}]` {txt}")
        
    return "\n".join(md)

def generate_kg_html():
    """ç”ŸæˆçŸ¥è¯†å›¾è°± HTML"""
    if not MEMORY: return "<div>No Data</div>"
    relations = MEMORY.get_all_kg_data(limit=300)
    
    G = nx.DiGraph()
    for r in relations:
        src = r.get('source', 'Unknown')
        tgt = r.get('target', 'Unknown')
        rel = r.get('relation', 'related')
        
        # ç®€å•åˆ†ç»„é¢œè‰²
        G.add_node(src, title=src, group=r.get('source_type', 'Object'))
        G.add_node(tgt, title=tgt, group=r.get('target_type', 'Object'))
        G.add_edge(src, tgt, label=rel)
    
    # PyVis é…ç½®
    net = Network(height="600px", width="100%", notebook=False, cdn_resources='remote', directed=True)
    net.from_nx(G)
    
    # å¼ºåˆ¶è®¾ç½®ç‰©ç†å¼•æ“å‚æ•°ï¼Œé˜²æ­¢ç™½å±
    net.set_options("""
    var options = {
      "nodes": { "font": { "size": 16 } },
      "physics": { "forceAtlas2Based": { "gravitationalConstant": -50, "springLength": 100 } }
    }
    """)
    
    return net.generate_html(name='kg.html', local=False)