# src/web_utils.py
import logging
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import json
import re
import networkx as nx
from pyvis.network import Network

# Path setup...
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import config
from src.memory.long_term_memory import LongTermMemory
from src.agent.master_agent import MasterAgent

logger = logging.getLogger(__name__)

# --- å•ä¾‹ ---
_memory_instance = None
_master_agent_instance = None

def get_memory_instance():
    global _memory_instance
    if _memory_instance is None:
        try:
            _memory_instance = LongTermMemory(config.LANCEDB_PATH, config.SQLITE_DB_PATH)
        except Exception as e:
            logger.error(f"Init Memory Failed: {e}")
    return _memory_instance

def get_master_agent():
    global _master_agent_instance
    if _master_agent_instance is None:
        mem = get_memory_instance()
        if mem: _master_agent_instance = MasterAgent(mem)
    return _master_agent_instance

MEMORY = get_memory_instance()
MASTER_AGENT = get_master_agent()

# --- è¾…åŠ©å‡½æ•° ---
def parse_summary(raw_summary):
    if not raw_summary: return "", "æ—¥å¸¸", 0
    parts = raw_summary.split("|||")
    text = parts[0]
    label = "æ—¥å¸¸"
    score = 0
    for p in parts:
        if p.startswith("LABEL:"): label = p.replace("LABEL:", "")
        if p.startswith("SCORE:"): 
            try: score = int(p.replace("SCORE:", ""))
            except: pass
    return text, label, score

# --- æ ¸å¿ƒï¼š8å¤§æŒ‡æ ‡è·å– ---
def get_dashboard_stats():
    """è·å–çœ‹æ¿æ‰€éœ€çš„ 8 ä¸ªæ ¸å¿ƒæŒ‡æ ‡"""
    if not MEMORY: return {}
    
    # åˆå§‹åŒ– 8 ä¸ªæŒ‡æ ‡
    stats = {
        "event_count": 0,       # 1. ä»Šæ—¥äº‹ä»¶æ•°
        "risk_count": 0,        # 2. é£é™©é¢„è­¦æ•°
        "active_hours": 0.0,    # 3. æ´»è·ƒæ—¶é•¿
        "rest_hours": 0.0,      # 4. ä¼‘æ¯æ—¶é•¿
        "max_inactive_min": 0,  # 5. æœ€å¤§é™æ­¢é—´éš”
        "social_count": 0,      # 6. ç¤¾äº¤/é«˜é¢‘äº’åŠ¨æ•°
        "family_count": 0,      # 7. å®¶äººæ¢è®¿(å»é‡äººæ•°)
        "new_knowledge": 0,     # 8. ä»Šæ—¥æ–°çŸ¥(å®ä½“æ•°)
        "last_active": "--:--"
    }
    
    today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).timestamp()
    
    try:
        with MEMORY.db_lock:
            cursor = MEMORY.sqlite_conn.cursor()
            
            # --- æŸ¥è¯¢ A: äº‹ä»¶ç›¸å…³ ---
            cursor.execute("SELECT start_time, end_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
            rows = cursor.fetchall()
            
            stats["event_count"] = len(rows)
            
            if rows:
                max_gap = 0
                last_end = rows[0][1]
                
                for i, r in enumerate(rows):
                    start, end, summary = r[0], r[1], r[2]
                    text, label, score = parse_summary(summary)
                    duration = end - start
                    
                    # ç»Ÿè®¡é€»è¾‘
                    if "é£é™©" in label or "è·Œå€’" in label or score >= 8:
                        stats["risk_count"] += 1
                    
                    if "èºº" in text or "ç¡" in text or "ä¼‘æ¯" in label:
                        stats["rest_hours"] += duration
                    else:
                        stats["active_hours"] += duration
                        
                    if score >= 4: # å‡è®¾è¯„åˆ†>4ç®—ä½œæœ‰äº’åŠ¨çš„ç¤¾äº¤/æŠ¤ç†
                        stats["social_count"] += 1
                        
                    # é™æ­¢é—´éš”
                    if i > 0:
                        gap = start - last_end
                        if gap > max_gap: max_gap = gap
                    last_end = end
                
                # è¡¥ç®—å½“å‰æ—¶åˆ»çš„é™æ­¢
                curr_gap = datetime.now().timestamp() - rows[-1][1]
                if curr_gap > max_gap: max_gap = curr_gap
                
                stats["max_inactive_min"] = int(max_gap / 60)
                stats["active_hours"] = round(stats["active_hours"] / 3600, 1)
                stats["rest_hours"] = round(stats["rest_hours"] / 3600, 1)
                stats["last_active"] = datetime.fromtimestamp(rows[-1][0]).strftime("%H:%M")

            # --- æŸ¥è¯¢ B: å®¶äºº/å®ä½“ç›¸å…³ ---
            # ç»Ÿè®¡ä»Šæ—¥æ¶‰åŠçš„éUnknownäººç‰©æ•°é‡
            cursor.execute("""
                SELECT COUNT(DISTINCT e.name) 
                FROM entities e
                JOIN relationships r ON e.id = r.source_id OR e.id = r.target_id
                JOIN events ev ON r.event_id = ev.event_id
                WHERE ev.start_time >= ? AND e.type = 'Person' AND e.name NOT LIKE '%Unknown%'
            """, (today_start,))
            stats["family_count"] = cursor.fetchone()[0]

            # ç»Ÿè®¡ä»Šæ—¥æ–°å¢å®ä½“(ç®€å•ç”¨å…³è”äº‹ä»¶æ—¶é—´ä¼°ç®—)
            # è¿™é‡Œç®€åŒ–é€»è¾‘ï¼šç»Ÿè®¡ä»Šæ—¥äº‹ä»¶å…³è”çš„æ‰€æœ‰å®ä½“æ•°
            cursor.execute("""
                SELECT COUNT(DISTINCT e.id)
                FROM entities e
                JOIN relationships r ON e.id = r.source_id OR e.id = r.target_id
                JOIN events ev ON r.event_id = ev.event_id
                WHERE ev.start_time >= ?
            """, (today_start,))
            stats["new_knowledge"] = cursor.fetchone()[0]
                
    except Exception as e:
        logger.error(f"Stats Error: {e}")
        
    return stats

def get_daily_insight_preview():
    """è·å–é¦–é¡µé¡¶éƒ¨çš„ä»Šæ—¥æ´å¯Ÿæ‘˜è¦"""
    now = datetime.now()
    
    # é€»è¾‘ï¼š22ç‚¹å‰æ˜¾ç¤ºè§‚å¯Ÿä¸­
    if now.hour < 22:
        return {
            "ready": False,
            "title": "ğŸ‘ï¸ ç©ºé—´æ€åŠ¿è§‚å¯Ÿä¸­...",
            "content": f"AI æ­£åœ¨æŒç»­åˆ†æä»Šæ—¥æ´»åŠ¨ã€‚å®Œæ•´æ—¥æŠ¥å°†äºä»Šæ™š **22:00** è‡ªåŠ¨ç”Ÿæˆã€‚\nç›®å‰ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå·²è®°å½• {get_dashboard_stats().get('event_count', 0)} ä¸ªäº‹ä»¶ç‰‡æ®µã€‚"
        }
    
    # 22ç‚¹åï¼šå¦‚æœæ²¡æœ‰ç”Ÿæˆè¿‡ï¼Œç°ç®—ä¸€ä¸ªç®€çŸ­çš„ï¼›å¦‚æœæƒ³çœ‹è¯¦ç»†çš„å»æŠ¥å‘Šé¡µ
    stats = get_dashboard_stats()
    summary = f"""
    **ğŸ“… ä»Šæ—¥æ¦‚è§ˆ (è‡ªåŠ¨ç”Ÿæˆ)**
    
    æˆªæ­¢ç›®å‰ï¼Œç³»ç»Ÿå…±è®°å½•äº† **{stats['event_count']}** ä¸ªæ´»åŠ¨ç‰‡æ®µã€‚
    é‡ç‚¹æ•°æ®å¦‚ä¸‹ï¼š
    - æ´»è·ƒæ—¶é•¿: {stats['active_hours']} å°æ—¶
    - ä¼‘æ¯æ—¶é•¿: {stats['rest_hours']} å°æ—¶
    - é£é™©é¢„è­¦: {stats['risk_count']} æ¬¡
    
    å»ºè®®æ‚¨ç‚¹å‡»å·¦ä¾§ **[ğŸ“ æŠ¥å‘Šç”Ÿæˆ]** æŸ¥çœ‹åŒ…å«è¯¦ç»†æ—¶é—´çº¿çš„å®Œæ•´åˆ†ææŠ¥å‘Šã€‚
    """
    return {
        "ready": True,
        "title": "âœ… ä»Šæ—¥æ—¥æŠ¥å·²å°±ç»ª",
        "content": summary
    }

def get_interaction_trend():
    """è·å–äº¤äº’çƒ­åº¦æ›²çº¿ (Area Chart)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT start_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
        rows = cursor.fetchall()
        
    data = []
    for r in rows:
        _, _, score = parse_summary(r[1])
        data.append({
            "Time": datetime.fromtimestamp(r[0]).strftime("%H:%M"),
            "Score": score
        })
    return pd.DataFrame(data)

def get_scene_distribution():
    """è·å–åœºæ™¯åˆ†å¸ƒ (Pie Chart)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT summary FROM events WHERE start_time >= ?", (today_start,))
        rows = cursor.fetchall()
        
    labels = []
    for r in rows:
        _, label, _ = parse_summary(r[0])
        labels.append(label)
        
    if not labels: return pd.DataFrame()
    
    # ç»Ÿè®¡å¹¶è½¬ä¸º DataFrame
    from collections import Counter
    counts = Counter(labels)
    return pd.DataFrame([{"Type": k, "Count": v} for k, v in counts.items()])


def get_person_frequency():
    """è·å–äººå‘˜å‡ºç°é¢‘ç‡ (DataFrame)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("""
            SELECT e.name FROM entities e
            JOIN relationships r ON e.id = r.source_id OR e.id = r.target_id
            JOIN events ev ON r.event_id = ev.event_id
            WHERE ev.start_time >= ? AND e.type = 'Person' AND e.name != 'Unknown_Body'
        """, (today_start,))
        rows = cursor.fetchall()
    
    names = [r[0] for r in rows]
    if not names: return pd.DataFrame()
    
    df = pd.DataFrame(names, columns=["Name"])
    return df["Name"].value_counts().reset_index(name="Count").rename(columns={"index": "Name"})

def get_system_stats():
    """è·å–ç³»ç»Ÿç¡¬æŒ‡æ ‡"""
    if not MEMORY: return {"memory": 0, "entities": 0, "care_hours": "0.0h"}
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM events")
        mem = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM entities")
        ent = cursor.fetchone()[0]
        cursor.execute("SELECT SUM(end_time - start_time) FROM events")
        row = cursor.fetchone()
        total_sec = row[0] if row[0] else 0
        
    return {
        "memory": mem,
        "entities": ent,
        "care_hours": f"{total_sec/3600:.1f}h"
    }

# --- é—®ç­” & æŠ¥å‘Š & å›¾è°± ---

def agent_answer_stream(query):
    """æµå¼è¿”å› Agent å›ç­”"""
    if not MASTER_AGENT:
        yield "System Initializing..."
        return
    # ä½¿ç”¨ execute_query_stepsï¼Œè€Œä¸æ˜¯ä¸å­˜åœ¨çš„ execute_query
    gen = MASTER_AGENT.execute_query_steps(query, lambda x: None)
    for step in gen:
        if step['status'] in ['generating', 'done']:
            yield step['content']

def generate_daily_report_content(date_obj=None):
    """
    ç”ŸæˆçœŸæ­£çš„ AI å™è¿°æ€§æ—¥æŠ¥
    """
    if not MEMORY: return "ç³»ç»Ÿæœªåˆå§‹åŒ–"
    if not date_obj: date_obj = datetime.now()
    
    start_ts = datetime.combine(date_obj, datetime.min.time()).timestamp()
    end_ts = datetime.combine(date_obj, datetime.max.time()).timestamp()
    
    # 1. è·å–åŸå§‹æ•°æ®
    events = MEMORY.get_events_for_period(start_ts, end_ts)
    if not events: return f"# ğŸ“… {date_obj.strftime('%Y-%m-%d')} æŠ¥å‘Š\n\nä»Šæ—¥æ— æ´»åŠ¨è®°å½•ã€‚"

    # 2. æ„å»ºä¸Šä¸‹æ–‡ç»™å¤§æ¨¡å‹
    context_lines = []
    for e in events:
        t = datetime.fromtimestamp(e['start_time']).strftime('%H:%M')
        txt, label, _ = parse_summary(e['summary'])
        context_lines.append(f"- [{t}] ({label}) {txt}")
    
    context_str = "\n".join(context_lines)
    
    # 3. è°ƒç”¨ MasterAgent ç”ŸæˆæŠ¥å‘Š (æˆ–è€…ç›´æ¥è°ƒ OpenAI)
    prompt = f"""
    ä½ æ˜¯ä¸€åä¸“ä¸šçš„å®¶åº­çœ‹æŠ¤åŠ©ç†ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä»Šæ—¥çš„æ´»åŠ¨æµæ°´ï¼Œå†™ä¸€ä»½ Markdown æ ¼å¼çš„æ—¥æŠ¥ã€‚
    
    è¦æ±‚ï¼š
    1. ä½¿ç”¨ä¸€çº§æ ‡é¢˜ï¼šğŸ“… {date_obj.strftime('%Y-%m-%d')} çœ‹æŠ¤æ—¥æŠ¥
    2. åŒ…å«â€œä»Šæ—¥æ¦‚è§ˆâ€ã€â€œè¯¦ç»†æ´»åŠ¨â€ã€â€œé£é™©æç¤ºâ€ä¸‰ä¸ªæ¿å—ã€‚
    3. è¯­æ°”æ¸©æš–ã€å®¢è§‚ã€‚
    4. é‡ç‚¹å…³æ³¨è€äººçš„æ´»åŠ¨é¢‘ç‡ã€ä¼‘æ¯æƒ…å†µå’Œæ˜¯å¦æœ‰å¼‚å¸¸ã€‚
    
    ã€æ´»åŠ¨æµæ°´ã€‘ï¼š
    {context_str}
    """
    
    try:
        if MASTER_AGENT:
            # å¤ç”¨ MasterAgent çš„ client
            resp = MASTER_AGENT.llm_client.chat.completions.create(
                model=config.AI_THINKING_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5
            )
            return resp.choices[0].message.content
        else:
            return "Agent æœªå°±ç»ªï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚"
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        return f"æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {e}\n\nåŸå§‹æ•°æ®:\n{context_str}"

def generate_kg_html():
    """ç”Ÿæˆå¢å¼ºç‰ˆçŸ¥è¯†å›¾è°± HTML"""
    if not MEMORY: return "<div>Memory Module Error</div>"
    
    # è·å–æ•°æ®
    relations = MEMORY.get_all_kg_data(limit=500)
    
    # å¦‚æœæ•°æ®ä¸ºç©ºï¼Œè¿”å›æç¤º
    if not relations:
        return """
        <div style='text-align:center; padding: 50px; color: #666;'>
            <h3>ğŸ•¸ï¸ æš‚æ— çŸ¥è¯†å›¾è°±æ•°æ®</h3>
            <p>è¯·å…ˆè¿è¡Œç³»ç»Ÿå¹¶ç­‰å¾…äº‹ä»¶åˆ†æå®Œæˆã€‚</p>
        </div>
        """
    
    G = nx.DiGraph()
    for r in relations:
        src = r.get('source', 'æœªçŸ¥').strip()
        tgt = r.get('target', 'æœªçŸ¥').strip()
        rel = r.get('relation', 'å…³è”').strip()
        
        if not src or not tgt: continue
        
        # æ ¹æ®ç±»å‹è®¾ç½®é¢œè‰²
        src_type = r.get('source_type', 'Object')
        tgt_type = r.get('target_type', 'Object')
        
        color_map = {
            "Person": "#ff7675", # çº¢
            "Object": "#74b9ff", # è“
            "Location": "#55efc4", # ç»¿
            "Activity": "#ffeaa7"  # é»„
        }
        
        G.add_node(src, label=src, color=color_map.get(src_type, "#dfe6e9"), title=src_type)
        G.add_node(tgt, label=tgt, color=color_map.get(tgt_type, "#dfe6e9"), title=tgt_type)
        G.add_edge(src, tgt, label=rel, color="#b2bec3")
    
    net = Network(height="650px", width="100%", notebook=False, cdn_resources='remote', directed=True)
    net.from_nx(G)
    
    # ç‰©ç†å¼•æ“é…ç½®ï¼šé˜²æ­¢çˆ†ç‚¸å’Œç©ºç™½
    net.set_options("""
    var options = {
      "nodes": { "font": { "size": 14, "face": "arial" }, "borderWidth": 1 },
      "edges": { "font": { "size": 10, "align": "middle" }, "arrows": { "to": { "enabled": true, "scaleFactor": 0.5 } } },
      "physics": { 
          "enabled": true,
          "forceAtlas2Based": { "gravitationalConstant": -50, "centralGravity": 0.01, "springLength": 100, "damping": 0.4 },
          "solver": "forceAtlas2Based",
          "stabilization": { "enabled": true, "iterations": 200 } 
      }
    }
    """)
    
    return net.generate_html(name='kg.html', local=False)