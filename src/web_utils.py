# src/web_utils.py
import logging
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import json
import re
import networkx as nx
from pyvis.network import Network

# è·¯å¾„è®¾ç½®
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import config
from src.memory.long_term_memory import LongTermMemory
from src.agent.master_agent import MasterAgent

logger = logging.getLogger(__name__)

# --- å•ä¾‹æ¨¡å¼å®ä¾‹åŒ– ---
_memory_instance = None
_master_agent_instance = None

def get_memory_instance():
    global _memory_instance
    if _memory_instance is None:
        try:
            logger.info("åˆå§‹åŒ– LongTermMemory...")
            _memory_instance = LongTermMemory(config.LANCEDB_PATH, config.SQLITE_DB_PATH)
        except Exception as e:
            logger.error(f"Memory Init Failed: {e}", exc_info=True)
    return _memory_instance

def get_master_agent():
    global _master_agent_instance
    if _master_agent_instance is None:
        mem = get_memory_instance()
        if mem:
            logger.info("åˆå§‹åŒ– MasterAgent...")
            _master_agent_instance = MasterAgent(mem)
    return _master_agent_instance

# å…¨å±€å®ä¾‹
MEMORY = get_memory_instance()
MASTER_AGENT = get_master_agent()

# --- è¾…åŠ©å‡½æ•° ---
def parse_summary(raw_summary):
    """è§£ææ‘˜è¦å­—ç¬¦ä¸²ï¼Œæå– Label å’Œ Score"""
    if not raw_summary: return "", "æ—¥å¸¸", 0
    parts = raw_summary.split("|||")
    text = parts[0]
    label = "æ—¥å¸¸"
    score = 0
    for p in parts:
        if p.startswith("LABEL:"): label = p.replace("LABEL:", "")
        if p.startswith("SCORE:"): 
            try: score = int(p.replace("SCORE:", ""))
            except: pass
    return text, label, score

# --- æ ¸å¿ƒæ•°æ®ç»Ÿè®¡ (Dashboard) ---
def get_dashboard_stats():
    """è·å–çœ‹æ¿æ‰€éœ€çš„ 8 ä¸ªæ ¸å¿ƒæŒ‡æ ‡"""
    if not MEMORY: return {}
    
    stats = {
        "event_count": 0, "risk_count": 0, "active_hours": 0.0, "rest_hours": 0.0,
        "max_inactive_min": 0, "social_count": 0, "family_count": 0, "new_knowledge": 0,
        "last_active": "--:--"
    }
    
    today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).timestamp()
    
    try:
        with MEMORY.db_lock:
            cursor = MEMORY.sqlite_conn.cursor()
            
            # 1. äº‹ä»¶ç»Ÿè®¡
            cursor.execute("SELECT start_time, end_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
            rows = cursor.fetchall()
            stats["event_count"] = len(rows)
            
            if rows:
                max_gap = 0
                last_end = rows[0][1]
                for i, r in enumerate(rows):
                    start, end, summary = r[0], r[1], r[2]
                    text, label, score = parse_summary(summary)
                    duration = end - start
                    
                    if "é£é™©" in label or "è·Œå€’" in label or score >= 8: stats["risk_count"] += 1
                    if "èºº" in text or "ç¡" in text or "ä¼‘æ¯" in label: stats["rest_hours"] += duration
                    else: stats["active_hours"] += duration
                    if score >= 4: stats["social_count"] += 1
                        
                    if i > 0:
                        gap = start - last_end
                        if gap > max_gap: max_gap = gap
                    last_end = end
                
                curr_gap = datetime.now().timestamp() - rows[-1][1]
                if curr_gap > max_gap: max_gap = curr_gap
                
                stats["max_inactive_min"] = int(max_gap / 60)
                stats["active_hours"] = round(stats["active_hours"] / 3600, 1)
                stats["rest_hours"] = round(stats["rest_hours"] / 3600, 1)
                stats["last_active"] = datetime.fromtimestamp(rows[-1][0]).strftime("%H:%M")

            # 2. å®¶äººç»Ÿè®¡ (é Unknown)
            cursor.execute("""
                SELECT COUNT(DISTINCT e.name) FROM entities e
                JOIN relationships r ON e.id = r.source_id OR e.id = r.target_id
                JOIN events ev ON r.event_id = ev.event_id
                WHERE ev.start_time >= ? AND e.type = 'Person' AND e.name NOT LIKE '%Unknown%'
            """, (today_start,))
            stats["family_count"] = cursor.fetchone()[0]

            # 3. æ–°çŸ¥ç»Ÿè®¡
            cursor.execute("""
                SELECT COUNT(DISTINCT e.id) FROM entities e
                JOIN relationships r ON e.id = r.source_id OR e.id = r.target_id
                JOIN events ev ON r.event_id = ev.event_id
                WHERE ev.start_time >= ?
            """, (today_start,))
            stats["new_knowledge"] = cursor.fetchone()[0]
                
    except Exception as e:
        logger.error(f"Stats Error: {e}")
        
    return stats

def get_daily_insight_preview():
    """é¦–é¡µæ¯æ—¥æ´å¯Ÿé€»è¾‘ (æ³¨æ„ï¼šè¿™é‡Œç”¨ HTML æ ‡ç­¾ <b> å®ç°åŠ ç²—)"""
    now = datetime.now()
    if now.hour < 22:
        return {
            "ready": False,
            "title": "ğŸ‘ï¸ ç©ºé—´æ€åŠ¿è§‚å¯Ÿä¸­...",
            "content": f"AI æ­£åœ¨æŒç»­åˆ†æä»Šæ—¥æ´»åŠ¨ã€‚å®Œæ•´æ—¥æŠ¥å°†äºä»Šæ™š <b>22:00</b> è‡ªåŠ¨ç”Ÿæˆã€‚\nç›®å‰å·²è®°å½• <b>{get_dashboard_stats().get('event_count', 0)}</b> ä¸ªäº‹ä»¶ç‰‡æ®µã€‚"
        }
    
    stats = get_dashboard_stats()
    summary = f"""
    <b>ğŸ“… ä»Šæ—¥æ—¥æŠ¥å·²å°±ç»ª</b><br>
    æˆªæ­¢ç›®å‰ï¼Œè®°å½•äº† {stats['event_count']} ä¸ªæ´»åŠ¨ç‰‡æ®µã€‚é£é™©å‘Šè­¦ {stats['risk_count']} æ¬¡ã€‚<br>
    å»ºè®®ç‚¹å‡»å·¦ä¾§ <b>[ğŸ“ æŠ¥å‘Šç”Ÿæˆ]</b> æŸ¥çœ‹æ·±åº¦åˆ†æã€‚
    """
    return {"ready": True, "title": "âœ… ä»Šæ—¥æ—¥æŠ¥å·²å°±ç»ª", "content": summary}

def get_interaction_trend():
    """äº¤äº’çƒ­åº¦æ•°æ®"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT start_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
        rows = cursor.fetchall()
    data = []
    for r in rows:
        _, _, score = parse_summary(r[1])
        data.append({"Time": datetime.fromtimestamp(r[0]).strftime("%H:%M"), "Score": score})
    return pd.DataFrame(data)

def get_scene_distribution():
    """åœºæ™¯åˆ†å¸ƒæ•°æ®"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT summary FROM events WHERE start_time >= ?", (today_start,))
        rows = cursor.fetchall()
    labels = []
    for r in rows:
        _, label, _ = parse_summary(r[0])
        labels.append(label)
    if not labels: return pd.DataFrame()
    from collections import Counter
    return pd.DataFrame([{"Type": k, "Count": v} for k, v in Counter(labels).items()])

def agent_answer_stream(query):
    """æµå¼é—®ç­”é€ä¼ """
    if not MASTER_AGENT:
        yield {"status": "answer", "content": "âš ï¸ ç³»ç»Ÿæœªå°±ç»ª"}
        return
    try:
        gen = MASTER_AGENT.execute_query_steps(query)
        for step in gen: yield step
    except Exception as e:
        yield {"status": "answer", "content": f"âš ï¸ é”™è¯¯: {e}"}

def generate_daily_report_content(date_obj=None):
    """
    ç”Ÿæˆå™è¿°æ€§æ—¥æŠ¥ (Prompt å‡çº§ç‰ˆ)
    """
    if not MEMORY: return "No Data"
    if not date_obj: date_obj = datetime.now()
    start_ts = datetime.combine(date_obj, datetime.min.time()).timestamp()
    end_ts = datetime.combine(date_obj, datetime.max.time()).timestamp()
    
    events = MEMORY.get_events_for_period(start_ts, end_ts)
    if not events: return f"# ğŸ“… {date_obj.strftime('%Y-%m-%d')} æŠ¥å‘Š\n\nå½“æ—¥æ— è®°å½•ã€‚"
    
    # æ„å»ºæµæ°´
    context_lines = []
    for e in events:
        t = datetime.fromtimestamp(e['start_time']).strftime('%H:%M')
        txt = e['summary'].split('|||')[0]
        context_lines.append(f"- [{t}] {txt}")
    context_str = "\n".join(context_lines)
    
    # --- å‡çº§åçš„ Promptï¼šå¼ºåˆ¶è¦æ±‚ç»¼åˆå™è¿° ---
    prompt = f"""
    ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å®¶åº­å¥åº·ç®¡ç†é¡¾é—®ã€‚è¯·é˜…è¯»ä»¥ä¸‹ç›‘æ§æµæ°´ï¼Œä¸ºç”¨æˆ·æ’°å†™ä¸€ä»½ã€å™è¿°æ€§ã€‘çš„æ·±åº¦æ—¥æŠ¥ã€‚
    
    ã€å…ƒæ•°æ®ã€‘
    æ—¥æœŸï¼š{date_obj.strftime('%Y-%m-%d')}
    äº‹ä»¶æµï¼š
    {context_str}
    
    ã€æ’°å†™è¦æ±‚ã€‘
    1. **ä¸è¦**æŒ‰æ—¶é—´æµæ°´è´¦ç½—åˆ—ï¼ˆä¸¥ç¦å‡ºç°â€œ15:00... 16:00...â€è¿™ç§åˆ—è¡¨æ ¼å¼ï¼‰ã€‚
    2. è¯·å°†ä¸€å¤©åˆ’åˆ†ä¸ºâ€œä¸Šåˆâ€ã€â€œä¸‹åˆâ€ã€â€œæ™šé—´â€ç­‰è‡ªç„¶æ®µè½è¿›è¡Œè¿è´¯çš„å™è¿°ã€‚
    3. æŠ¥å‘Šç»“æ„å¦‚ä¸‹ï¼š
       - **ğŸ“ ä»Šæ—¥ç”Ÿæ´»ç”»åƒ**ï¼šç”¨ä¸€æ®µä¼˜ç¾çš„æ–‡å­—æ¦‚æ‹¬è€äººä»Šå¤©çš„ä¸»è¦æ´»åŠ¨è½¨è¿¹å’Œç²¾ç¥çŠ¶æ€ã€‚
       - **ğŸ©º å¥åº·æ·±åº¦è¯„ä¼°**ï¼šåˆ†æå…¶è¿åŠ¨é‡ã€ä¼‘æ¯è§„å¾‹ã€å–æ°´é¢‘ç‡ã€ä¹…åæƒ…å†µç­‰ã€‚
       - **âš ï¸ å¼‚å¸¸é£é™©æ£€æµ‹**ï¼šæ˜ç¡®æŒ‡å‡ºæ˜¯å¦å­˜åœ¨è·Œå€’é£é™©ã€æœªå…³é—¨çª—ã€é™Œç”Ÿäººè¿›å…¥ç­‰å®‰å…¨éšæ‚£ã€‚
       - **ğŸ’¡ ä¸“å±å…³æ€€å»ºè®®**ï¼šç»™å‡ºæš–å¿ƒçš„ã€å¯æ‰§è¡Œçš„ç”Ÿæ´»å»ºè®®ã€‚
    4. è¯­æ°”è¦æ¸©æš–ã€ä¸“ä¸šã€ä½“ç°å¯¹é•¿è€…çš„å…³æ€€ã€‚
    
    è¯·ç›´æ¥è¾“å‡º Markdown å†…å®¹ã€‚
    """
    
    try:
        if MASTER_AGENT:
            resp = MASTER_AGENT.llm_client.chat.completions.create(
                model=config.AI_THINKING_MODEL, 
                messages=[{"role": "user", "content": prompt}], 
                temperature=0.6 # ç¨å¾®æé«˜æ¸©åº¦ï¼Œè®©æ–‡ç¬”æ›´å¥½
            )
            return resp.choices[0].message.content
        return "Agent æœªå°±ç»ªã€‚"
    except Exception as e:
        return f"ç”Ÿæˆå‡ºé”™: {e}"

def generate_kg_html():
    """ç”Ÿæˆå¸¦å¼€åœºåŠ¨ç”»çš„çŸ¥è¯†å›¾è°±"""
    if not MEMORY: return "<div>No Data</div>"
    relations = MEMORY.get_all_kg_data(limit=500)
    if not relations: return "<div style='text-align:center;padding:50px;color:#666'>æš‚æ— çŸ¥è¯†å›¾è°±æ•°æ®</div>"
    
    G = nx.DiGraph()
    # é…è‰²ä¼˜åŒ–
    color_map = {
        "Person": "#FF6B6B",   # æš–çº¢
        "Object": "#4ECDC4",   # é’ç»¿
        "Location": "#FFE66D", # äº®é»„
        "Activity": "#1A535C"  # æ·±è“
    }
    
    for r in relations:
        src, tgt = r.get('source', 'U'), r.get('target', 'U')
        G.add_node(src, label=src, color=color_map.get(r.get('source_type'), "#f7f1e3"), title=r.get('source_type'))
        G.add_node(tgt, label=tgt, color=color_map.get(r.get('target_type'), "#f7f1e3"), title=r.get('target_type'))
        G.add_edge(src, tgt, label=r.get('relation', '-'), color="#bdc3c7")
    
    net = Network(height="750px", width="100%", notebook=False, cdn_resources='remote', directed=True)
    net.from_nx(G)
    
    # --- å…³é”®ï¼šç‰©ç†å¼•æ“è®¾ç½® ---
    # stabilization: false -> æ„å‘³ç€ä¸€å¼€å§‹ä¸è®¡ç®—ç¨³å®šçŠ¶æ€ï¼Œç›´æ¥å±•ç¤ºä»æ··ä¹±åˆ°æœ‰åºçš„åŠ¨ç”»è¿‡ç¨‹
    net.set_options("""
    var options = {
      "nodes": { "font": { "size": 16, "face": "tahoma" }, "borderWidth": 2, "shadow": true },
      "edges": { "width": 1, "smooth": { "type": "continuous" }, "arrows": { "to": { "scaleFactor": 0.5 } } },
      "physics": { 
          "enabled": true,
          "forceAtlas2Based": { "gravitationalConstant": -60, "centralGravity": 0.01, "springLength": 100, "springConstant": 0.08, "damping": 0.4 },
          "maxVelocity": 50,
          "solver": "forceAtlas2Based",
          "stabilization": { "enabled": false } 
      }
    }
    """)
    return net.generate_html(name='kg.html', local=False)