# src/web_utils.py
import logging
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import json
import re
import networkx as nx
from pyvis.network import Network

# ç¡®ä¿èƒ½æ‰¾åˆ°srcç›®å½•
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import config
from src.memory.long_term_memory import LongTermMemory
from src.agent.master_agent import MasterAgent

logger = logging.getLogger(__name__)

# --- å•ä¾‹æ¨¡å¼å®ä¾‹åŒ– ---
_memory_instance = None
_master_agent_instance = None

def get_memory_instance():
    global _memory_instance
    if _memory_instance is None:
        try:
            logger.info("Initializing LongTermMemory instance for web app...")
            _memory_instance = LongTermMemory(config.LANCEDB_PATH, config.SQLITE_DB_PATH)
        except Exception as e:
            logger.error(f"Failed to initialize LongTermMemory: {e}", exc_info=True)
    return _memory_instance

def get_master_agent():
    global _master_agent_instance
    if _master_agent_instance is None:
        memory = get_memory_instance()
        if memory:
            logger.info("Initializing MasterAgent instance for web app...")
            _master_agent_instance = MasterAgent(memory)
    return _master_agent_instance

# --- å…¨å±€å®ä¾‹ ---
MEMORY = get_memory_instance()
MASTER_AGENT = get_master_agent()

# --- æ ¸å¿ƒå·¥å…·å‡½æ•° ---

def parse_summary(raw_summary):
    """
    è§£ææ‰©å±•æ‘˜è¦ï¼Œæå–æ–‡æœ¬ã€æ ‡ç­¾å’Œè¯„åˆ†ã€‚
    è¾“å…¥æ ¼å¼: "æ‘˜è¦æ–‡æœ¬...|||LABEL:xxx|||SCORE:5"
    """
    if not raw_summary: return "", "æœªçŸ¥", 0
    
    parts = raw_summary.split("|||")
    text = parts[0]
    label = "æ—¥å¸¸"
    score = 0
    
    for p in parts:
        if p.startswith("LABEL:"): 
            label = p.replace("LABEL:", "")
        if p.startswith("SCORE:"): 
            try: score = int(p.replace("SCORE:", ""))
            except: pass
            
    return text, label, score

# --- æ•°æ®èšåˆä¸ç»Ÿè®¡ (Dashboard) ---

def get_dashboard_stats():
    """è·å–çœ‹æ¿æ‰€éœ€çš„ 4 ä¸ªæ ¸å¿ƒæŒ‡æ ‡"""
    if not MEMORY: return {}
    
    stats = {
        "event_count": 0,
        "risk_count": 0,
        "max_inactive_min": 0,
        "rest_hours": 0.0,
        "last_active": "--:--"
    }
    
    today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).timestamp()
    
    try:
        with MEMORY.db_lock:
            cursor = MEMORY.sqlite_conn.cursor()
            
            # 1. è·å–ä»Šæ—¥æ‰€æœ‰äº‹ä»¶
            cursor.execute("SELECT start_time, end_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
            rows = cursor.fetchall()
            
            stats["event_count"] = len(rows)
            
            if rows:
                max_gap = 0
                rest_sec = 0
                risk_alerts = 0
                last_end = rows[0][1]
                
                for i, r in enumerate(rows):
                    start, end, summary = r[0], r[1], r[2]
                    text, label, _ = parse_summary(summary)
                    
                    # ç»Ÿè®¡é£é™©
                    if "è·Œå€’" in text or "é£é™©" in label or "æ±‚æ•‘" in text:
                        risk_alerts += 1
                        
                    # ç»Ÿè®¡ä¼‘æ¯ (æ ‡ç­¾åŒ…å«å•äººä¸”æ–‡æœ¬æœ‰ç¡/èºº)
                    if "èºº" in text or "ç¡" in text or "ä¼‘æ¯" in text:
                        rest_sec += (end - start)
                        
                    # ç»Ÿè®¡é™æ­¢é—´éš”
                    if i > 0:
                        gap = start - last_end
                        if gap > max_gap: max_gap = gap
                    last_end = end
                
                # å½“å‰æ—¶åˆ»è·ç¦»æœ€åä¸€ä¸ªäº‹ä»¶çš„é—´éš”
                curr_gap = datetime.now().timestamp() - rows[-1][1]
                if curr_gap > max_gap: max_gap = curr_gap
                
                stats["max_inactive_min"] = int(max_gap / 60)
                stats["rest_hours"] = round(rest_sec / 3600, 1)
                stats["risk_count"] = risk_alerts
                stats["last_active"] = datetime.fromtimestamp(rows[-1][0]).strftime("%H:%M")
                
    except Exception as e:
        logger.error(f"Stats Error: {e}")
        
    return stats

def get_interaction_trend():
    """è·å–äº¤äº’çƒ­åº¦æ›²çº¿æ•°æ® (DataFrame)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT start_time, summary FROM events WHERE start_time >= ? ORDER BY start_time", (today_start,))
        rows = cursor.fetchall()
        
    data = []
    for r in rows:
        _, _, score = parse_summary(r[1])
        data.append({
            "Time": datetime.fromtimestamp(r[0]).strftime("%H:%M"),
            "Score": score
        })
    return pd.DataFrame(data)

def get_scene_distribution():
    """è·å–åœºæ™¯æ ‡ç­¾åˆ†å¸ƒ (DataFrame)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT summary FROM events WHERE start_time >= ?", (today_start,))
        rows = cursor.fetchall()
        
    labels = []
    for r in rows:
        _, label, _ = parse_summary(r[0])
        labels.append(label)
        
    if not labels: return pd.DataFrame()
    df = pd.DataFrame(labels, columns=["Type"])
    return df["Type"].value_counts().reset_index(name="Count").rename(columns={"index": "Type"}) # Pandas å…¼å®¹æ€§å†™æ³•

def get_person_frequency():
    """è·å–äººå‘˜å‡ºç°é¢‘ç‡ (DataFrame)"""
    if not MEMORY: return pd.DataFrame()
    today_start = datetime.now().replace(hour=0, minute=0, second=0).timestamp()
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("""
            SELECT e.name FROM entities e
            JOIN relationships r ON e.id = r.source_id OR e.id = r.target_id
            JOIN events ev ON r.event_id = ev.event_id
            WHERE ev.start_time >= ? AND e.type = 'Person' AND e.name != 'Unknown_Body'
        """, (today_start,))
        rows = cursor.fetchall()
    
    names = [r[0] for r in rows]
    if not names: return pd.DataFrame()
    
    df = pd.DataFrame(names, columns=["Name"])
    return df["Name"].value_counts().reset_index(name="Count").rename(columns={"index": "Name"})

def get_system_stats():
    """è·å–ç³»ç»Ÿç¡¬æŒ‡æ ‡"""
    if not MEMORY: return {"memory": 0, "entities": 0, "care_hours": "0.0h"}
    
    with MEMORY.db_lock:
        cursor = MEMORY.sqlite_conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM events")
        mem = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM entities")
        ent = cursor.fetchone()[0]
        cursor.execute("SELECT SUM(end_time - start_time) FROM events")
        row = cursor.fetchone()
        total_sec = row[0] if row[0] else 0
        
    return {
        "memory": mem,
        "entities": ent,
        "care_hours": f"{total_sec/3600:.1f}h"
    }

# --- é—®ç­” & æŠ¥å‘Š & å›¾è°± ---

def agent_answer_stream(query):
    """æµå¼è¿”å› Agent å›ç­”"""
    if not MASTER_AGENT:
        yield "System Initializing..."
        return
    # ä½¿ç”¨ execute_query_stepsï¼Œè€Œä¸æ˜¯ä¸å­˜åœ¨çš„ execute_query
    gen = MASTER_AGENT.execute_query_steps(query, lambda x: None)
    for step in gen:
        if step['status'] in ['generating', 'done']:
            yield step['content']

def generate_daily_report_content(date_obj=None):
    """
    ç”ŸæˆçœŸæ­£çš„ AI å™è¿°æ€§æ—¥æŠ¥
    """
    if not MEMORY: return "ç³»ç»Ÿæœªåˆå§‹åŒ–"
    if not date_obj: date_obj = datetime.now()
    
    start_ts = datetime.combine(date_obj, datetime.min.time()).timestamp()
    end_ts = datetime.combine(date_obj, datetime.max.time()).timestamp()
    
    # 1. è·å–åŸå§‹æ•°æ®
    events = MEMORY.get_events_for_period(start_ts, end_ts)
    if not events: return f"# ğŸ“… {date_obj.strftime('%Y-%m-%d')} æŠ¥å‘Š\n\nä»Šæ—¥æ— æ´»åŠ¨è®°å½•ã€‚"

    # 2. æ„å»ºä¸Šä¸‹æ–‡ç»™å¤§æ¨¡å‹
    context_lines = []
    for e in events:
        t = datetime.fromtimestamp(e['start_time']).strftime('%H:%M')
        txt, label, _ = parse_summary(e['summary'])
        context_lines.append(f"- [{t}] ({label}) {txt}")
    
    context_str = "\n".join(context_lines)
    
    # 3. è°ƒç”¨ MasterAgent ç”ŸæˆæŠ¥å‘Š (æˆ–è€…ç›´æ¥è°ƒ OpenAI)
    prompt = f"""
    ä½ æ˜¯ä¸€åä¸“ä¸šçš„å®¶åº­çœ‹æŠ¤åŠ©ç†ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä»Šæ—¥çš„æ´»åŠ¨æµæ°´ï¼Œå†™ä¸€ä»½ Markdown æ ¼å¼çš„æ—¥æŠ¥ã€‚
    
    è¦æ±‚ï¼š
    1. ä½¿ç”¨ä¸€çº§æ ‡é¢˜ï¼šğŸ“… {date_obj.strftime('%Y-%m-%d')} çœ‹æŠ¤æ—¥æŠ¥
    2. åŒ…å«â€œä»Šæ—¥æ¦‚è§ˆâ€ã€â€œè¯¦ç»†æ´»åŠ¨â€ã€â€œé£é™©æç¤ºâ€ä¸‰ä¸ªæ¿å—ã€‚
    3. è¯­æ°”æ¸©æš–ã€å®¢è§‚ã€‚
    4. é‡ç‚¹å…³æ³¨è€äººçš„æ´»åŠ¨é¢‘ç‡ã€ä¼‘æ¯æƒ…å†µå’Œæ˜¯å¦æœ‰å¼‚å¸¸ã€‚
    
    ã€æ´»åŠ¨æµæ°´ã€‘ï¼š
    {context_str}
    """
    
    try:
        if MASTER_AGENT:
            # å¤ç”¨ MasterAgent çš„ client
            resp = MASTER_AGENT.llm_client.chat.completions.create(
                model=config.AI_THINKING_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5
            )
            return resp.choices[0].message.content
        else:
            return "Agent æœªå°±ç»ªï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚"
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        return f"æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {e}\n\nåŸå§‹æ•°æ®:\n{context_str}"

def generate_kg_html():
    """ç”Ÿæˆå¢å¼ºç‰ˆçŸ¥è¯†å›¾è°± HTML"""
    if not MEMORY: return "<div>Memory Module Error</div>"
    
    # è·å–æ•°æ®
    relations = MEMORY.get_all_kg_data(limit=500)
    
    # å¦‚æœæ•°æ®ä¸ºç©ºï¼Œè¿”å›æç¤º
    if not relations:
        return """
        <div style='text-align:center; padding: 50px; color: #666;'>
            <h3>ğŸ•¸ï¸ æš‚æ— çŸ¥è¯†å›¾è°±æ•°æ®</h3>
            <p>è¯·å…ˆè¿è¡Œç³»ç»Ÿå¹¶ç­‰å¾…äº‹ä»¶åˆ†æå®Œæˆã€‚</p>
        </div>
        """
    
    G = nx.DiGraph()
    for r in relations:
        src = r.get('source', 'æœªçŸ¥').strip()
        tgt = r.get('target', 'æœªçŸ¥').strip()
        rel = r.get('relation', 'å…³è”').strip()
        
        if not src or not tgt: continue
        
        # æ ¹æ®ç±»å‹è®¾ç½®é¢œè‰²
        src_type = r.get('source_type', 'Object')
        tgt_type = r.get('target_type', 'Object')
        
        color_map = {
            "Person": "#ff7675", # çº¢
            "Object": "#74b9ff", # è“
            "Location": "#55efc4", # ç»¿
            "Activity": "#ffeaa7"  # é»„
        }
        
        G.add_node(src, label=src, color=color_map.get(src_type, "#dfe6e9"), title=src_type)
        G.add_node(tgt, label=tgt, color=color_map.get(tgt_type, "#dfe6e9"), title=tgt_type)
        G.add_edge(src, tgt, label=rel, color="#b2bec3")
    
    net = Network(height="650px", width="100%", notebook=False, cdn_resources='remote', directed=True)
    net.from_nx(G)
    
    # ç‰©ç†å¼•æ“é…ç½®ï¼šé˜²æ­¢çˆ†ç‚¸å’Œç©ºç™½
    net.set_options("""
    var options = {
      "nodes": { "font": { "size": 14, "face": "arial" }, "borderWidth": 1 },
      "edges": { "font": { "size": 10, "align": "middle" }, "arrows": { "to": { "enabled": true, "scaleFactor": 0.5 } } },
      "physics": { 
          "enabled": true,
          "forceAtlas2Based": { "gravitationalConstant": -50, "centralGravity": 0.01, "springLength": 100, "damping": 0.4 },
          "solver": "forceAtlas2Based",
          "stabilization": { "enabled": true, "iterations": 200 } 
      }
    }
    """)
    
    return net.generate_html(name='kg.html', local=False)